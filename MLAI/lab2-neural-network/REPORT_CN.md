# Lab 2 实验报告：神经网络

## 摘要
本实验使用PyTorch构建前馈神经网络，完成MNIST手写数字识别。通过对比不同学习率的影响，分析了神经网络的训练过程和性能。

## 1. 实验内容

### Task 1: 张量变换
演示了两种方法将tensor [2,3,5]变换为[10,3]:
- **方法1: repeat()** - 实际复制数据
- **方法2: expand()** - 创建视图，不复制数据

**差异**: expand()内存效率更高

### Task 2: Softmax函数
Softmax将原始输出转换为概率分布，用于多分类任务：
$$\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$$

### Task 3-4: 模型训练
- 网络结构: 784→128→128→256→256→10
- 激活函数: ReLU + Softmax
- 损失函数: Cross Entropy
- 优化器: SGD
- 训练轮数: 20 epochs

### Task 5: 混淆矩阵
展示了每个数字类别的识别准确率，对角线元素表示正确分类。

### Task 6: 学习率对比
测试了lr=0.02, 0.1, 0.5三种学习率：
- lr=0.02: 收敛慢但稳定
- lr=0.1: 平衡状态
- lr=0.5: 收敛快但可能震荡

## 2. 结果分析
较高学习率加速收敛但可能不稳定，较低学习率收敛慢但更稳定。选择合适的学习率对训练至关重要。

## 3. 结论
成功实现了手写数字识别系统，准确率达90%以上。学习率是影响训练效果的关键超参数。
